# üîç RELAT√ìRIO DE VERIFICA√á√ÉO - CONSULTA DATALAKE (90 DIAS)

**Data da An√°lise:** 17/11/2025  
**Autor:** An√°lise Automatizada  
**Status:** ‚ö†Ô∏è DADOS DESATUALIZADOS

---

## üìã RESUMO EXECUTIVO

### Situa√ß√£o Encontrada
- **Arquivo de Dados:** `resultados/dados_com_duracao_20251104_130000.csv`
- **Data de Extra√ß√£o:** 04/11/2025 √†s 13:00
- **√öltima Atualiza√ß√£o:** H√° **35 dias** (dados desatualizados)
- **Status dos Dados:** ‚ö†Ô∏è **PARCIALMENTE DESATUALIZADOS**

### ‚ö†Ô∏è PROBLEMA IDENTIFICADO

Os dados **N√ÉO est√£o** trazendo os √∫ltimos 90 dias completos:

| M√©trica | Esperado | Encontrado | Status |
|---------|----------|------------|--------|
| **Per√≠odo de Cobertura** | 19/08/2025 - 17/11/2025 | 21/08/2025 - 13/10/2025 | ‚ö†Ô∏è Incompleto |
| **Total de Dias** | 90 dias | 53 dias | ‚ùå 37 dias faltando |
| **Dias com Dados** | ~90 dias | 23 dias | ‚ö†Ô∏è Cobertura de 25.6% |
| **Data Mais Recente** | 17/11/2025 (hoje) | 13/10/2025 | ‚ùå 35 dias atrasado |

---

## üìä AN√ÅLISE DETALHADA DOS DADOS

### Estrutura dos Dados Encontrados

**Total de Registros:** 200  
**Usu√°rios √önicos:** 19  
**Total de Horas:** 942.87h  
**M√©dia por Apontamento:** 4.71h

### Per√≠odo Coberto

```
Data Inicial:    21/08/2025
Data Final:      13/10/2025
Dias Cobertos:   53 dias
Dias com Dados:  23 dias
```

### Top 5 Usu√°rios (per√≠odo analisado)

1. **Rosiane Lopes dos Santos** - 117.18h
2. **Viviane Alves Dos Santos** - 73.13h
3. **Jo√£o Vitor Veiga Alves** - 69.37h
4. **Karina Oliveira Inacio** - 68.58h
5. **Renan Siciliano de Oliveira** - 66.90h

### üî¥ Lacunas Identificadas

**33 datas sem apontamentos** nos √∫ltimos 90 dias, incluindo:
- 19/08/2025 (Tuesday)
- 20/08/2025 (Wednesday)
- 23/08/2025 (Saturday)
- 24/08/2025 (Sunday)
- ... e mais 29 datas

---

## üîé ARQUIVO DE CONSULTA AO DATALAKE

### ‚ùå ARQUIVO N√ÉO ENCONTRADO

O sistema faz refer√™ncia a um arquivo chamado **`analise_duracao_trabalho.py`** que deveria fazer a consulta ao Microsoft Fabric Data Warehouse, mas este arquivo **n√£o foi encontrado** no reposit√≥rio atual.

### Refer√™ncias no C√≥digo

O arquivo √© mencionado em:
- `agente_apontamentos.py` (linha ~33): `"Execute: python analise_duracao_trabalho.py"`
- `teste_novas_funcionalidades.py`
- `teste_ia_conversacional.py`

### üìÅ Localiza√ß√£o Esperada

```
blocks_teams/
‚îú‚îÄ‚îÄ analise_duracao_trabalho.py   ‚ùå N√ÉO ENCONTRADO
‚îú‚îÄ‚îÄ agente_apontamentos.py         ‚úÖ Existe (l√™ os CSVs)
‚îî‚îÄ‚îÄ resultados/
    ‚îî‚îÄ‚îÄ dados_com_duracao_*.csv    ‚úÖ Existe (dados desatualizados)
```

---

## üí° EXEMPLO DE QUERY SQL PARA DATALAKE

### Query Recomendada (Microsoft Fabric Data Warehouse)

```sql
-- ============================================================
-- CONSULTA DATALAKE - √öLTIMOS 90 DIAS
-- Data: @DATA_ATUAL
-- Objetivo: Extrair apontamentos dos √∫ltimos 90 dias
-- ============================================================

SELECT 
    s_id_apontamento,
    s_ds_operacao,
    s_nr_contrato,
    s_nr_cpf,
    s_id_recurso,
    s_nm_recurso,
    s_id_cargo,
    s_ds_cargo,
    d_dt_data,
    d_dt_data_fim,
    d_dt_inicio_apontamento,
    d_dt_fim_apontamento,
    f_hr_hora_inicio,
    f_hr_hora_fim,
    n_fl_abatimento,
    b_fl_validado,
    s_id_usuario_valida,
    s_nm_usuario_valida,
    s_id_usuario,
    s_nm_usuario,
    s_id_tipo_jornada,
    s_ds_tipo_jornada,
    s_id_divisao,
    s_ds_divisao,
    s_nm_sigla,
    s_nm_cliente_operacional,
    d_dt_inicio_apontamento AS dt_inicio,
    d_dt_fim_apontamento AS dt_fim,
    
    -- Calcular dura√ß√£o em horas
    DATEDIFF(HOUR, d_dt_inicio_apontamento, d_dt_fim_apontamento) AS duracao_horas
    
FROM 
    [schema].[tabela_apontamentos]  -- AJUSTAR NOME DA TABELA
    
WHERE 
    -- FILTRO CR√çTICO: √öLTIMOS 90 DIAS
    d_dt_data >= DATEADD(DAY, -90, GETDATE())
    AND d_dt_data <= GETDATE()
    
    -- Filtros adicionais (opcional)
    AND b_fl_validado = 1  -- Apenas validados
    
ORDER BY 
    d_dt_data DESC,
    s_nm_recurso;
```

### Verifica√ß√£o da Query

Para garantir que est√° trazendo 90 dias:

```sql
-- Query de verifica√ß√£o
SELECT 
    MIN(d_dt_data) AS data_minima,
    MAX(d_dt_data) AS data_maxima,
    DATEDIFF(DAY, MIN(d_dt_data), MAX(d_dt_data)) AS total_dias,
    COUNT(*) AS total_registros,
    COUNT(DISTINCT s_nm_recurso) AS total_usuarios,
    COUNT(DISTINCT CAST(d_dt_data AS DATE)) AS dias_com_dados
FROM 
    [schema].[tabela_apontamentos]
WHERE 
    d_dt_data >= DATEADD(DAY, -90, GETDATE());
```

**Resultado Esperado:**
- `total_dias` deve ser pr√≥ximo de 90
- `dias_com_dados` depende dos dias √∫teis com apontamentos

---

## üîß CONFIGURA√á√ÉO NO .ENV

```env
# Microsoft Fabric Data Warehouse
FABRIC_ENDPOINT=your-endpoint.datawarehouse.fabric.microsoft.com
FABRIC_DATABASE=your-database-name

# Azure AD Authentication
AZURE_CLIENT_ID=your-azure-ad-client-id
AZURE_CLIENT_SECRET=your-azure-ad-client-secret
AZURE_TENANT_ID=3a78b0cd-7c8e-4929-83d5-190a6cc01365
```

---

## üìù SCRIPT DE EXTRA√á√ÉO MODELO (Python)

```python
"""
Script para extrair dados do Microsoft Fabric Data Warehouse
Consulta os √∫ltimos 90 dias de apontamentos
"""

import pyodbc
import pandas as pd
from datetime import datetime
import os
from dotenv import load_dotenv

load_dotenv()

def extrair_dados_fabric():
    """Extrai dados dos √∫ltimos 90 dias do Fabric Data Warehouse"""
    
    # Configura√ß√µes de conex√£o
    server = os.getenv('FABRIC_ENDPOINT')
    database = os.getenv('FABRIC_DATABASE')
    
    # String de conex√£o Microsoft Fabric
    connection_string = f'''
    Driver={{ODBC Driver 18 for SQL Server}};
    Server=tcp:{server},1433;
    Database={database};
    Authentication=ActiveDirectoryInteractive;
    Encrypt=yes;
    TrustServerCertificate=no;
    '''
    
    try:
        print("üîó Conectando ao Microsoft Fabric...")
        conn = pyodbc.connect(connection_string)
        
        # Query SQL com filtro de 90 dias
        query = """
        SELECT 
            *,
            DATEDIFF(HOUR, d_dt_inicio_apontamento, d_dt_fim_apontamento) AS duracao_horas
        FROM 
            [schema].[tabela_apontamentos]
        WHERE 
            d_dt_data >= DATEADD(DAY, -90, GETDATE())
            AND d_dt_data <= GETDATE()
        ORDER BY 
            d_dt_data DESC
        """
        
        print("üì• Executando consulta SQL...")
        df = pd.read_sql(query, conn)
        
        print(f"‚úÖ {len(df)} registros extra√≠dos")
        
        # Salvar CSV
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'resultados/dados_com_duracao_{timestamp}.csv'
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        
        print(f"üíæ Dados salvos em: {filename}")
        
        conn.close()
        return df
        
    except Exception as e:
        print(f"‚ùå Erro ao conectar: {e}")
        return None

if __name__ == "__main__":
    extrair_dados_fabric()
```

---

## ‚úÖ A√á√ïES RECOMENDADAS

### 1. **URGENTE - Atualizar Dados**

```bash
# Executar script de extra√ß√£o
python analise_duracao_trabalho.py
# ou
python extrair_dados_fabric.py
```

### 2. **Verificar Query SQL**

- [ ] Confirmar se a query no script de extra√ß√£o tem o filtro: `DATEADD(DAY, -90, GETDATE())`
- [ ] Verificar se a tabela e schema est√£o corretos
- [ ] Testar conex√£o com Microsoft Fabric Data Warehouse

### 3. **Validar Resultado**

```bash
# Ap√≥s atualizar os dados, executar:
python verificar_90_dias.py
```

**Resultado esperado:**
- Cobertura: > 80% dos √∫ltimos 90 dias
- Data mais recente: hoje ou ontem
- Status: COMPLETO

### 4. **Automa√ß√£o (Recomendado)**

Configurar job autom√°tico para extrair dados:
- **Periodicidade:** Di√°ria (preferencialmente √† noite)
- **Hor√°rio:** 23:00 - 01:00
- **Ferramenta:** Azure Data Factory, Airflow, ou Cron Job

---

## üìä MONITORAMENTO

### M√©tricas para Acompanhar

1. **Tempo desde √∫ltima atualiza√ß√£o** (deve ser < 24h)
2. **Cobertura dos √∫ltimos 90 dias** (deve ser > 80%)
3. **Total de registros** (crescimento esperado)
4. **Usu√°rios ativos** (comparar com m√™s anterior)

### Script de Monitoramento

```python
# verificar_90_dias.py (j√° criado)
python verificar_90_dias.py
```

---

## üìö DOCUMENTA√á√ÉO RELACIONADA

- **Microsoft Fabric Docs:** https://learn.microsoft.com/fabric/
- **ODBC Driver 18:** https://learn.microsoft.com/sql/connect/odbc/
- **PyODBC:** https://github.com/mkleehammer/pyodbc

---

## üéØ CONCLUS√ÉO

### Status Atual
‚ùå **Os dados N√ÉO est√£o trazendo os √∫ltimos 90 dias completos**

### Problemas Identificados
1. ‚ùå Arquivo de extra√ß√£o (`analise_duracao_trabalho.py`) n√£o encontrado
2. ‚ùå Dados desatualizados (√∫ltima atualiza√ß√£o h√° 35 dias)
3. ‚ùå Cobertura parcial (apenas 25.6% dos √∫ltimos 90 dias)
4. ‚ö†Ô∏è Lacunas significativas nos dados

### Pr√≥ximos Passos
1. üîç **Localizar ou criar** o script de extra√ß√£o do datalake
2. ‚úÖ **Verificar** a query SQL para garantir filtro de 90 dias
3. üîÑ **Executar** extra√ß√£o atualizada
4. ‚úîÔ∏è **Validar** com `verificar_90_dias.py`
5. ü§ñ **Automatizar** processo de extra√ß√£o

---

**√öltima Atualiza√ß√£o:** 17/11/2025  
**Pr√≥xima Revis√£o:** Ap√≥s atualiza√ß√£o dos dados
