"""
ü§ñ M√ìDULO DE CONVERSA√á√ÉO COM IA
Processamento de linguagem natural para consultas sobre apontamentos
Usa Azure OpenAI ou OpenAI para interpreta√ß√£o inteligente
"""

import os
import json
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import pandas as pd

try:
    from openai import AzureOpenAI, OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("‚ö†Ô∏è openai n√£o instalado. Execute: pip install openai")


class ConversacaoIA:
    """
    Gerencia conversa√ß√µes inteligentes sobre dados de apontamentos
    usando GPT para interpreta√ß√£o de linguagem natural
    """
    
    def __init__(self, agente_apontamentos):
        """
        Inicializa o m√≥dulo de conversa√ß√£o
        
        Args:
            agente_apontamentos: Inst√¢ncia do AgenteApontamentos com os dados
        """
        self.agente = agente_apontamentos
        self.historico_conversas = {}  # {user_id: [mensagens]}
        self.client = None
        self.model = None
        
        # Configurar cliente OpenAI
        self._configurar_cliente()
    
    def _configurar_cliente(self):
        """Configura cliente OpenAI (Azure ou OpenAI direto)"""
        if not OPENAI_AVAILABLE:
            print("‚ö†Ô∏è OpenAI n√£o dispon√≠vel - modo fallback")
            return
        
        try:
            # Tentar Azure OpenAI primeiro
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            azure_key = os.getenv("AZURE_OPENAI_KEY")
            azure_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4")
            
            if azure_endpoint and azure_key:
                self.client = AzureOpenAI(
                    api_key=azure_key,
                    api_version="2024-02-15-preview",
                    azure_endpoint=azure_endpoint
                )
                self.model = azure_deployment
                print("‚úÖ Azure OpenAI configurado")
                return
            
            # Fallback para OpenAI direto
            openai_key = os.getenv("OPENAI_API_KEY")
            if openai_key:
                self.client = OpenAI(api_key=openai_key)
                self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
                print("‚úÖ OpenAI configurado")
                return
            
            print("‚ö†Ô∏è Nenhuma chave de API configurada - modo fallback")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao configurar OpenAI: {e}")
    
    def _obter_contexto_dados(self) -> str:
        """Prepara contexto sobre os dados dispon√≠veis"""
        if self.agente.df is None:
            return "Dados n√£o dispon√≠veis no momento."
        
        df = self.agente.df
        
        # Estat√≠sticas b√°sicas
        total_registros = len(df)
        total_horas = df['duracao_horas'].sum()
        media_horas = df['duracao_horas'].mean()
        
        # Per√≠odo dos dados
        data_min = df['data'].min() if 'data' in df.columns else None
        data_max = df['data'].max() if 'data' in df.columns else None
        
        # Top usu√°rios
        top_usuarios = df.groupby('s_nm_recurso')['duracao_horas'].sum().nlargest(5)
        
        contexto = f"""
CONTEXTO DOS DADOS DE APONTAMENTOS:

**Estat√≠sticas Gerais:**
- Total de registros: {total_registros}
- Total de horas: {total_horas:.2f}h
- M√©dia de horas por apontamento: {media_horas:.2f}h
- Per√≠odo: {data_min} at√© {data_max}

**Top 5 Usu√°rios (por horas):**
{top_usuarios.to_string()}

**Colunas dispon√≠veis:**
- s_nm_recurso: Nome do funcion√°rio
- duracao_horas: Dura√ß√£o do apontamento em horas
- data: Data do apontamento
- s_ds_operacao: Descri√ß√£o da opera√ß√£o
"""
        return contexto
    
    def _criar_prompt_sistema(self) -> str:
        """Cria o prompt do sistema com contexto dos dados"""
        return f"""Voc√™ √© um assistente inteligente especializado em an√°lise de dados de apontamentos de trabalho.
Seu objetivo √© ajudar usu√°rios a consultar e entender os dados de forma simples e direta.

{self._obter_contexto_dados()}

**DIRETRIZES:**
1. Seja CONCISO e DIRETO - respostas curtas e objetivas
2. Use emojis para tornar as respostas mais amig√°veis
3. Sempre formate n√∫meros (use v√≠rgula para decimais, ex: 8,5h)
4. Se n√£o souber algo, diga que n√£o tem essa informa√ß√£o
5. Sugira consultas quando apropriado
6. N√£o invente dados - use apenas o que est√° dispon√≠vel

**FERRAMENTAS DISPON√çVEIS:**
Voc√™ pode solicitar que eu execute fun√ß√µes para obter dados espec√≠ficos:
- duracao_media_geral(): M√©dia geral de horas
- duracao_media_usuario(nome): M√©dia de um usu√°rio espec√≠fico
- apontamentos_hoje(usuario): Apontamentos de hoje
- ranking_funcionarios(): Top funcion√°rios por horas
- total_horas_usuario(nome): Total de horas de um usu√°rio
- identificar_outliers(): Apontamentos fora do padr√£o
- resumo_semanal(usuario): Resumo da semana
- comparar_periodos(): Comparar semanas

Para usar uma ferramenta, responda no formato:
FERRAMENTA: nome_da_funcao(parametros)

Exemplo de conversa:
User: "quantas horas eu trabalhei?"
Assistant: FERRAMENTA: total_horas_usuario(Usuario Nome)

User: "qual a m√©dia geral?"
Assistant: FERRAMENTA: duracao_media_geral()"""
    
    def _extrair_ferramenta(self, resposta_ia: str) -> Optional[Tuple[str, Dict]]:
        """
        Extrai chamada de ferramenta da resposta da IA
        
        Returns:
            (nome_funcao, parametros) ou None
        """
        if "FERRAMENTA:" not in resposta_ia:
            return None
        
        try:
            # Extrair linha com FERRAMENTA:
            for linha in resposta_ia.split('\n'):
                if "FERRAMENTA:" in linha:
                    chamada = linha.split("FERRAMENTA:")[1].strip()
                    
                    # Parse simples: nome_funcao(param1, param2)
                    if '(' in chamada:
                        nome = chamada.split('(')[0].strip()
                        params_str = chamada.split('(')[1].split(')')[0]
                        
                        # Converter para dict
                        params = {}
                        if params_str.strip():
                            # Por simplicidade, assumir apenas um par√¢metro
                            params['arg'] = params_str.strip().strip('"\'')
                        
                        return (nome, params)
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao extrair ferramenta: {e}")
        
        return None
    
    def _executar_ferramenta(self, nome: str, params: Dict, usuario: str) -> Dict:
        """Executa fun√ß√£o do agente"""
        try:
            if nome == "duracao_media_geral":
                return self.agente.duracao_media_geral()
            
            elif nome == "duracao_media_usuario":
                user = params.get('arg', usuario)
                return self.agente.duracao_media_usuario(user)
            
            elif nome == "apontamentos_hoje":
                return self.agente.apontamentos_hoje(usuario)
            
            elif nome == "ranking_funcionarios":
                return self.agente.ranking_funcionarios()
            
            elif nome == "total_horas_usuario":
                user = params.get('arg', usuario)
                return self.agente.total_horas_usuario(user)
            
            elif nome == "identificar_outliers":
                return self.agente.identificar_outliers()
            
            elif nome == "resumo_semanal":
                return self.agente.resumo_semanal(usuario)
            
            elif nome == "comparar_periodos":
                return self.agente.comparar_periodos()
            
            else:
                return {"erro": f"Ferramenta '{nome}' n√£o encontrada"}
        
        except Exception as e:
            return {"erro": f"Erro ao executar ferramenta: {e}"}
    
    def processar_mensagem(self, mensagem: str, usuario: str) -> Dict:
        """
        Processa mensagem do usu√°rio com IA
        
        Args:
            mensagem: Mensagem do usu√°rio
            usuario: Nome do usu√°rio
        
        Returns:
            Dict com resposta e dados
        """
        # Se IA n√£o dispon√≠vel, usar fallback
        if not self.client:
            return self._fallback_processar(mensagem, usuario)
        
        try:
            # Obter hist√≥rico do usu√°rio
            if usuario not in self.historico_conversas:
                self.historico_conversas[usuario] = []
            
            historico = self.historico_conversas[usuario]
            
            # Construir mensagens
            mensagens = [
                {"role": "system", "content": self._criar_prompt_sistema()}
            ]
            
            # Adicionar hist√≥rico (√∫ltimas 5 mensagens)
            mensagens.extend(historico[-5:])
            
            # Adicionar mensagem atual
            mensagens.append({"role": "user", "content": f"[Usu√°rio: {usuario}] {mensagem}"})
            
            # Chamar IA
            response = self.client.chat.completions.create(
                model=self.model,
                messages=mensagens,
                temperature=0.7,
                max_tokens=500
            )
            
            resposta_ia = response.choices[0].message.content
            
            # Verificar se IA solicitou ferramenta
            ferramenta = self._extrair_ferramenta(resposta_ia)
            
            if ferramenta:
                nome_func, params = ferramenta
                
                # Executar ferramenta
                resultado = self._executar_ferramenta(nome_func, params, usuario)
                
                # Pedir para IA formatar resposta
                mensagens.append({"role": "assistant", "content": resposta_ia})
                mensagens.append({
                    "role": "user", 
                    "content": f"RESULTADO DA FERRAMENTA: {json.dumps(resultado, ensure_ascii=False)}\n\nAgora formate isso de forma amig√°vel e concisa para o usu√°rio."
                })
                
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=mensagens,
                    temperature=0.7,
                    max_tokens=300
                )
                
                resposta_final = response.choices[0].message.content
                
                # Atualizar hist√≥rico
                historico.append({"role": "user", "content": mensagem})
                historico.append({"role": "assistant", "content": resposta_final})
                
                return {
                    "resposta": resposta_final,
                    "dados": resultado.get('dados', {}),
                    "tipo": resultado.get('tipo', 'ia_conversacao'),
                    "usa_ia": True
                }
            
            else:
                # Resposta direta da IA
                historico.append({"role": "user", "content": mensagem})
                historico.append({"role": "assistant", "content": resposta_ia})
                
                return {
                    "resposta": resposta_ia,
                    "tipo": "ia_conversacao",
                    "usa_ia": True
                }
        
        except Exception as e:
            print(f"‚ùå Erro ao processar com IA: {e}")
            return self._fallback_processar(mensagem, usuario)
    
    def _fallback_processar(self, mensagem: str, usuario: str) -> Dict:
        """Fallback quando IA n√£o est√° dispon√≠vel"""
        # Usar l√≥gica existente do agente
        return self.agente.responder_pergunta(mensagem, usuario)
    
    def limpar_historico(self, usuario: str):
        """Limpa hist√≥rico de conversa√ß√£o de um usu√°rio"""
        if usuario in self.historico_conversas:
            self.historico_conversas[usuario] = []
